{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand skills list with dutch skills \n",
    "import pandas as pd\n",
    "df_tags=pd.read_csv(\"tags.csv\")\n",
    "SKILLS_DB = df_tags.name.str.lower().tolist()\n",
    "SKILLS_DB_DICT ={}\n",
    "for x in SKILLS_DB:\n",
    "    SKILLS_DB_DICT[x] = x\n",
    "SKILLS_DB_DICT[\"programma manager\"] = \"program manager\"\n",
    "SKILLS_DB_DICT[\"zelfstandig\"] = \"independent\"\n",
    "SKILLS_DB_DICT[\"autonoom\"] = \"independent\"\n",
    "SKILLS_DB_DICT[\"nederlands\"] = \"dutch\"\n",
    "SKILLS_DB_DICT[\"engels\"] = \"english\"\n",
    "SKILLS_DB_DICT[\"frans\"] = \"french\"\n",
    "SKILLS_DB_DICT[\"duits\"] = \"german\"\n",
    "SKILLS_DB_DICT[\"accountant\"] = \"auditor\"\n",
    "SKILLS_DB_DICT[\"applicatiebeheerder\"] = \"application administrator\"\n",
    "SKILLS_DB_DICT[\"logistiek\"] = \"logistics\"\n",
    "SKILLS_DB_DICT[\"digitale transformatie\"] = \"digital transformation\"\n",
    "SKILLS_DB_DICT[\"functioneel analist\"] = \"functional analyst\"\n",
    "SKILLS_DB_DICT[\"business analist\"] = \"business analyst\"\n",
    "SKILLS_DB_DICT[\"project ingenieur\"] = \"project engineer\"\n",
    "SKILLS_DB_DICT[\"data analist\"] = \"data analyst\"\n",
    "SKILLS_DB_DICT[\"data science\"] = \"data scientist\"\n",
    "SKILLS_DB_DICT[\"analist\"] = \"analyst\"\n",
    "SKILLS_DB_DICT[\"strategie\"] = \"strategy\"\n",
    "SKILLS_DB_DICT[\"qlik\"] = \"qlik (view/sense)\"\n",
    "SKILLS_DB_DICT[\"automatisatie\"] = \"automation\"\n",
    "SKILLS_DB_DICT[\"packaging engineer\"] = \"packaging engineer/specialist\"\n",
    "SKILLS_DB_DICT[\"packaging specialist\"] = \"packaging engineer/specialist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coo': 'coo',\n",
       " 'external party mngmt': 'external party mngmt',\n",
       " 'it architect': 'it architect',\n",
       " '.net': '.net',\n",
       " 'symfony': 'symfony',\n",
       " 'android': 'android',\n",
       " 'green field': 'green field',\n",
       " 'cobol': 'cobol',\n",
       " 'treasury': 'treasury',\n",
       " 'front end developer': 'front end developer',\n",
       " 'telecom': 'telecom',\n",
       " 'crm': 'crm',\n",
       " 'audit': 'audit',\n",
       " 'program manager': 'program manager',\n",
       " 'business developer': 'business developer',\n",
       " 'life science': 'life science',\n",
       " 'angular': 'angular',\n",
       " 'independent': 'independent',\n",
       " 'it delivery': 'it delivery',\n",
       " 'lean six sigma': 'lean six sigma',\n",
       " 'django': 'django',\n",
       " 'dutch': 'dutch',\n",
       " 'english': 'english',\n",
       " 'french': 'french',\n",
       " 'german': 'german',\n",
       " 'student': 'student',\n",
       " 'auditor': 'auditor',\n",
       " 'application adminstrator': 'application adminstrator',\n",
       " 'data scientist': 'data scientist',\n",
       " 'machine learning': 'machine learning',\n",
       " 'itil': 'itil',\n",
       " 'data manager': 'data manager',\n",
       " 'network security': 'network security',\n",
       " 'digital transformation manager': 'digital transformation manager',\n",
       " 'bpmn': 'bpmn',\n",
       " 'agile coach': 'agile coach',\n",
       " 'finance': 'finance',\n",
       " 'test coordinator': 'test coordinator',\n",
       " 'ios': 'ios',\n",
       " 'logistics': 'logistics',\n",
       " 'cyber security': 'cyber security',\n",
       " 'iot': 'iot',\n",
       " 'fmcg': 'fmcg',\n",
       " 'digital transformation': 'digital transformation',\n",
       " 'sap': 'sap',\n",
       " 'oracle': 'oracle',\n",
       " 'sap fi/co': 'sap fi/co',\n",
       " 'drupal': 'drupal',\n",
       " 'project manager': 'project manager',\n",
       " 'functional analyst': 'functional analyst',\n",
       " 'business analyst': 'business analyst',\n",
       " 'scrum master': 'scrum master',\n",
       " 'laravel': 'laravel',\n",
       " 'project engineer': 'project engineer',\n",
       " 'recruiter': 'recruiter',\n",
       " 'security architect': 'security architect',\n",
       " 'erp': 'erp',\n",
       " 'cloud': 'cloud',\n",
       " 'civil engineer': 'civil engineer',\n",
       " 'enterprise architect': 'enterprise architect',\n",
       " 'packaging': 'packaging',\n",
       " 'software engineer': 'software engineer',\n",
       " 'testing': 'testing',\n",
       " 'soa': 'soa',\n",
       " 'bpo': 'bpo',\n",
       " 'data analyst': 'data analyst',\n",
       " 'process engineer': 'process engineer',\n",
       " 'aem': 'aem',\n",
       " 'business architect': 'business architect',\n",
       " 'windev': 'windev',\n",
       " 'product manager': 'product manager',\n",
       " 'engineering': 'engineering',\n",
       " 'developer': 'developer',\n",
       " 'pmo': 'pmo',\n",
       " 'cad': 'cad',\n",
       " 'interim manager': 'interim manager',\n",
       " 'analyst': 'analyst',\n",
       " 'energy': 'energy',\n",
       " 'php': 'php',\n",
       " 'it': 'it',\n",
       " 'business process analyst': 'business process analyst',\n",
       " 'java': 'java',\n",
       " 'facility management': 'facility management',\n",
       " 'change management': 'change management',\n",
       " 'supply chain': 'supply chain',\n",
       " 'strategy': 'strategy',\n",
       " 'qlik (view/sense)': 'qlik (view/sense)',\n",
       " 'agile': 'agile',\n",
       " 'software architect': 'software architect',\n",
       " 'uml': 'uml',\n",
       " 'management': 'management',\n",
       " 'technical support engineer': 'technical support engineer',\n",
       " 'c++': 'c++',\n",
       " 'service management': 'service management',\n",
       " 'python': 'python',\n",
       " 'qt': 'qt',\n",
       " 'solution architect': 'solution architect',\n",
       " 'agile transformation': 'agile transformation',\n",
       " 'automation': 'automation',\n",
       " 'product owner': 'product owner',\n",
       " 'customer care': 'customer care',\n",
       " 'ai': 'ai',\n",
       " 'react': 'react',\n",
       " 'marketing': 'marketing',\n",
       " 'operations engineer': 'operations engineer',\n",
       " 'testing manager': 'testing manager',\n",
       " 'technical writer': 'technical writer',\n",
       " 'prince2': 'prince2',\n",
       " 'safety engineer': 'safety engineer',\n",
       " 'packaging engineer/specialist': 'packaging engineer/specialist',\n",
       " 'quality engineer': 'quality engineer',\n",
       " 'six sigma': 'six sigma',\n",
       " 'domain architecture': 'domain architecture',\n",
       " 'jira': 'jira',\n",
       " 'mobility & transport': 'mobility & transport',\n",
       " 'scrum': 'scrum',\n",
       " 'retail': 'retail',\n",
       " 'togaf': 'togaf',\n",
       " 'testing engineer': 'testing engineer',\n",
       " 'r&d': 'r&d',\n",
       " 'treasurer': 'treasurer',\n",
       " 'azure': 'azure',\n",
       " 'financial controller': 'financial controller',\n",
       " 'infrastructure project manager': 'infrastructure project manager',\n",
       " 'technical lead': 'technical lead',\n",
       " 'navision': 'navision',\n",
       " 'bi': 'bi',\n",
       " 'business transformation mngr': 'business transformation mngr',\n",
       " 'business controller': 'business controller',\n",
       " 'product analyst': 'product analyst',\n",
       " 'controlling officer': 'controlling officer',\n",
       " 'programma manager': 'program manager',\n",
       " 'zelfstandig': 'independent',\n",
       " 'autonoom': 'independent',\n",
       " 'nederlands': 'dutch',\n",
       " 'engels': 'english',\n",
       " 'frans': 'french',\n",
       " 'duits': 'german',\n",
       " 'accountant': 'auditor',\n",
       " 'applicatiebeheerder': 'application administrator',\n",
       " 'logistiek': 'logistics',\n",
       " 'digitale transformatie': 'digital transformation',\n",
       " 'functioneel analist': 'functional analyst',\n",
       " 'business analist': 'business analyst',\n",
       " 'project ingenieur': 'project engineer',\n",
       " 'data analist': 'data analyst',\n",
       " 'data science': 'data scientist',\n",
       " 'analist': 'analyst',\n",
       " 'strategie': 'strategy',\n",
       " 'qlik': 'qlik (view/sense)',\n",
       " 'automatisatie': 'automation',\n",
       " 'packaging engineer': 'packaging engineer/specialist',\n",
       " 'packaging specialist': 'packaging engineer/specialist'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SKILLS_DB_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JefRutten\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import docx2txt\n",
    "import nltk\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "df_tags=pd.read_csv(\"tags.csv\")\n",
    "\n",
    "SKILLS_DB = df_tags.name.str.lower().tolist()\n",
    "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    "\n",
    "def preprocessing_text(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text.lower())\n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "    \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in filtered_tokens if w not in stop_words]\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "def extract_skills(input_text):\n",
    "    if input_text == [\"error\"]:\n",
    "        found_skills = \"error\"\n",
    "    else:\n",
    "        input_text = preprocessing_text(input_text)\n",
    "        # generate bigrams and trigrams (such as artificial intelligence)\n",
    "        bigrams_trigrams = list(map(' '.join, nltk.everygrams(input_text, 2, 3)))\n",
    "\n",
    "        # we create a set to keep the results in.\n",
    "        found_skills = set()\n",
    "\n",
    "        # we search for each token in our skills database\n",
    "        for token in input_text:\n",
    "            if token.lower() in SKILLS_DB_DICT.keys():\n",
    "                found_skills.add(SKILLS_DB_DICT[token])\n",
    "\n",
    "        # we search for each bigram and trigram in our skills database\n",
    "        for ngram in bigrams_trigrams:\n",
    "            if ngram.lower() in SKILLS_DB_DICT.keys():\n",
    "                found_skills.add(SKILLS_DB_DICT[ngram.lower()])\n",
    "\n",
    "    return found_skills\n",
    "\n",
    "def extract_names(txt):\n",
    "    person_names = []\n",
    "\n",
    "    for sent in nltk.sent_tokenize(txt):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "                person_names.append(\n",
    "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
    "                )\n",
    "\n",
    "    return person_names[0],person_names[1]\n",
    "\n",
    "def extract_names_NER(text):\n",
    "    nlp = spacy.load(\"nl_core_news_sm\")\n",
    "    doc = nlp(text)\n",
    "    start =[]\n",
    "    stop=[]\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            start.append(ent.start_char)\n",
    "            stop.append(ent.end_char)\n",
    "            #print(ent.text,ent.start_char,ent.end_char)\n",
    "    name = text[start[0]:stop[0]]\n",
    "    first_name = name.split(\" \")[0]\n",
    "    try:\n",
    "        last_name = name.split(\" \")[1]\n",
    "    except:\n",
    "        last_name = text[start[1]:stop[1]]\n",
    "    return first_name,last_name\n",
    "\n",
    "def extract_phone_number(resume_text):\n",
    "    if resume_text == [\"error\"]:\n",
    "        found_number = \"error\"\n",
    "    else:\n",
    "    \n",
    "        phone = re.findall(PHONE_REG, resume_text)\n",
    "        list =[]\n",
    "        list2 =[]\n",
    "        for i in phone:\n",
    "            list.append(i.replace(' ', '').replace('.','') .replace('+','').replace(')','').replace('(','').replace('+','').replace('-',''))\n",
    "        for i in list:\n",
    "            if len(i)>8:\n",
    "                list2.append(i)\n",
    "        if list2:\n",
    "            found_number = ''.join(list2[0])\n",
    "        else: found_number = \"nan\"\n",
    "\n",
    "    return found_number\n",
    "\n",
    "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    "\n",
    "def extract_emails(resume_text):\n",
    "    if resume_text == [\"error\"]:\n",
    "        emails = [\"error\"]\n",
    "    else:\n",
    "        emails = re.findall(EMAIL_REG, resume_text.lower())\n",
    "        if emails:\n",
    "            return emails[0]\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    if resume_text == [\"error\"]:\n",
    "        first_name,last_name = [\"error\",\"error\"]\n",
    "    else:\n",
    "        nlp_text = nlp(resume_text)\n",
    "\n",
    "        # First name and Last name are always Proper Nouns\n",
    "        pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "\n",
    "        matcher.add('NAME',[pattern])\n",
    "\n",
    "        matches = matcher(nlp_text)\n",
    "\n",
    "        if nlp_text[matches[0][1]:matches[0][2]] is not \"curriculum vitae\":\n",
    "            span = nlp_text[matches[0][1]:matches[0][2]]\n",
    "        else:\n",
    "            span = nlp_text[matches[1][1]:matches[1][2]]\n",
    "\n",
    "        first_name = span[0]\n",
    "        last_name = span[1]\n",
    "    return first_name,last_name\n",
    "\n",
    "def parse_id(candidate_id):\n",
    "    try:\n",
    "        dirs = os.listdir(sys.path[0]+'/candidates/'+candidate_id)\n",
    "    except:\n",
    "        print(\"map not opening for candidate: {}\".format(candidate_id))\n",
    "        dirs = []\n",
    "    try:\n",
    "        a = dirs[0]\n",
    "        path = sys.path[0]+'/candidates/'+candidate_id+'/'+a\n",
    "    except:\n",
    "        print(\"map empty for candidate: {}\".format(candidate_id))\n",
    "    \n",
    "    if len(dirs) > 0:\n",
    "        \n",
    "        # This would print all the files and directories\n",
    "        # This would print all the files and directories\n",
    "        try:\n",
    "            with open(path, 'rb') as f:            \n",
    "                if path[-4:] == \"docx\":\n",
    "                    text = extract_text_from_docx(f)\n",
    "                elif path[-4:] == \".pdf\":\n",
    "                    text = extract_text(f)\n",
    "                else:\n",
    "                    text = ['error']\n",
    "        except:\n",
    "            text =[\"error\"]\n",
    "        try:\n",
    "            skills = extract_skills(text)\n",
    "        except:\n",
    "            print(\"skills not working for candidate: {}\".format(candidate_id))\n",
    "            skills ='error'\n",
    "        try:\n",
    "            number = extract_phone_number(text)\n",
    "        except:\n",
    "            print(\"number not working for candidate: {}\".format(candidate_id))\n",
    "            number ='error'\n",
    "        try:\n",
    "            mail = extract_emails(text)\n",
    "        except:\n",
    "            print(\"number not working for candidate: {}\".format(candidate_id))\n",
    "            mail = 'error'\n",
    "        try:\n",
    "            first_name,last_name = extract_name(text)\n",
    "        except:\n",
    "            print(\"extract names not working for candidate: {}\".format(candidate_id))\n",
    "            first_name,last_name = ['error','error']\n",
    "        try:\n",
    "            first_name2,last_name2 = extract_names(text)\n",
    "        except:\n",
    "            print(\"extract names 2 not working for candidate: {}\".format(candidate_id))\n",
    "            first_name2,last_name2 = ['error','error']      \n",
    "        try:\n",
    "            first_name3,last_name3 = extract_names_NER(text)\n",
    "        except:\n",
    "            print(\"extract names 3 not working for candidate: {}\".format(candidate_id))\n",
    "            first_name3,last_name3 = ['error','error']\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        skills,number,mail, first_name, last_name,first_name2,last_name2,first_name3,last_name3 = ['nan','nan','nan','nan','nan','nan','nan','nan','nan']\n",
    "    return skills, number, mail, first_name, last_name,first_name2,last_name2,first_name3,last_name3 \n",
    "\n",
    "\n",
    "def parse_id_lbk(candidate_id):\n",
    "    try:\n",
    "        dirs = os.listdir(sys.path[0]+'/candidates/'+candidate_id+'/candidates/scripts/LBK/')\n",
    "    except:\n",
    "        print(\"map not opening for candidate: {}\".format(candidate_id))\n",
    "        dirs = []\n",
    "    try:\n",
    "        a = dirs[0]\n",
    "        path = sys.path[0]+'/candidates/'+candidate_id+'/candidates/scripts/LBK/'+a\n",
    "    except:\n",
    "        print(\"map empty for candidate: {}\".format(candidate_id))\n",
    "    \n",
    "    if len(dirs) > 0:\n",
    "        \n",
    "        # This would print all the files and directories\n",
    "        # This would print all the files and directories\n",
    "        try:\n",
    "            with open(path, 'rb') as f:            \n",
    "                if path[-4:] == \"docx\":\n",
    "                    text = extract_text_from_docx(f)\n",
    "                elif path[-4:] == \".pdf\":\n",
    "                    text = extract_text(f)\n",
    "                   \n",
    "                else:\n",
    "                    text = ['error']\n",
    "        except:\n",
    "            text =[\"error\"]\n",
    "        try:\n",
    "            skills = extract_skills(text)\n",
    "        except:\n",
    "            print(\"skills not working for candidate: {}\".format(candidate_id))\n",
    "            skills ='error'\n",
    "        try:\n",
    "            number = extract_phone_number(text)\n",
    "        except:\n",
    "            print(\"number not working for candidate: {}\".format(candidate_id))\n",
    "            number ='error'\n",
    "        try:\n",
    "            mail = extract_emails(text)\n",
    "        except:\n",
    "            print(\"number not working for candidate: {}\".format(candidate_id))\n",
    "            mail = 'error'\n",
    "        try:\n",
    "            first_name,last_name = extract_name(text)\n",
    "        except:\n",
    "            print(\"extract names not working for candidate: {}\".format(candidate_id))\n",
    "            first_name,last_name = ['error','error']\n",
    "        try:\n",
    "            first_name2,last_name2 = extract_names(text)\n",
    "        except:\n",
    "            print(\"extract names 2 not working for candidate: {}\".format(candidate_id))\n",
    "            first_name2,last_name2 = ['error','error']      \n",
    "        try:\n",
    "            first_name3,last_name3 = extract_names_NER(text)\n",
    "        except:\n",
    "            print(\"extract names 3 not working for candidate: {}\".format(candidate_id))\n",
    "            first_name3,last_name3 = ['error','error']       \n",
    "\n",
    "    else:\n",
    "        skills,number,mail, first_name, last_name,first_name2,last_name2,first_name3,last_name3 = ['nan','nan','nan','nan','nan','nan','nan','nan','nan']\n",
    "    return skills, number, mail, first_name, last_name,first_name2,last_name2,first_name3,last_name3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"helaas kan de data omtrent CV's en de nimbus database niet gedeeld worden, om toch een POC demonstratie te kunnen delen.\\ndeel ik 2 CV's waarvan ik toestemming heb om deze te delen, deze kunnen gebruikt worden tijdens de trial\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"helaas kan de data omtrent CV's en de nimbus database niet gedeeld worden, om toch een POC demonstratie te kunnen delen.\n",
    "deel ik 2 CV's waarvan ik toestemming heb om deze te delen, deze kunnen gebruikt worden tijdens de trial\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maak een map aan candidates, vervolgens een map jef en plaats hier de CV'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"maak een map aan candidates, vervolgens een map jef en plaats hier de CV\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dutch', 'engineering', 'english', 'french', 'logistics'},\n",
       " '32494062706',\n",
       " 'jefrutten@hotmail.com',\n",
       " CURRICULUM,\n",
       " VITAE,\n",
       " 'Leuven',\n",
       " 'België Major',\n",
       " 'Minor',\n",
       " 'Skikot')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_id('jef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"results:\n",
    "we zien dat de tags, tel nr en e-mail succesvol zijn geëxtraheerd\n",
    "we zien voor first name en last name dat er fouten zijn gemaakt in alle gebruikte methodes POS pattern mathcing, NER nltk en NER spacy\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"voeg in de map candidates een map yanne toe, vervolgens plaats de CV in deze map\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bi',\n",
       "  'dutch',\n",
       "  'english',\n",
       "  'fmcg',\n",
       "  'french',\n",
       "  'management',\n",
       "  'retail',\n",
       "  'student'},\n",
       " '32487527728',\n",
       " 'yannebillen@hotmail.com',\n",
       " Yanne,\n",
       " Billen,\n",
       " 'Yanne',\n",
       " 'Billen WORK',\n",
       " 'Yanne',\n",
       " 'Billen')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_id('yanne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"results:\n",
    "we zien dat de tags, tel nr en e-mail succesvol zijn geëxtraheerd\n",
    "ook de naam is succesvol bij POS pattern matching en NER door spacy\n",
    "bij NER nltk is er iets misgelopen bij de achternaam\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
